{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils\n",
    "import scoring\n",
    "import catboost\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 34.4 s, total: 3min 7s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = utils.load_train_hdf(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 1.95 s, total: 15.5 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_hdf(DATA_PATH + '/test_public.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 s, sys: 1.84 s, total: 15 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test2 = pd.read_hdf(DATA_PATH + '/test_public.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 6.26 s, total: 32.7 s\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_private = pd.read_hdf(DATA_PATH + '/test_private_v2_track_1.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 5.26 s, total: 30.6 s\n",
      "Wall time: 30.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_private2 = pd.read_hdf(DATA_PATH + '/test_private_v2_track_1.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### После добавления информативных признаков, мы их сохраним и будем быстро добавлять из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 457 ms, sys: 531 ms, total: 987 ms\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features = pd.read_hdf('data_itog.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.4 ms, sys: 731 ms, total: 798 ms\n",
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features2 = pd.read_hdf(DATA_PATH + '/data_itog2.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.4 ms, sys: 104 ms, total: 111 ms\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features_test = pd.read_hdf(DATA_PATH + '/data_itog_test.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 117 ms, total: 117 ms\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features_test2 = pd.read_hdf(DATA_PATH + '/data_itog_test2.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closest_hits_features_test_private = pd.read_hdf(DATA_PATH + '/data_itog_test_private.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closest_hits_features_test_private2 = pd.read_hdf(DATA_PATH + '/data_itog_test_private2.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_hits = pd.read_hdf('avg_dist_hits.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_hits_test = pd.read_hdf('avg_dist_hits_test.hdf', axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "KILL_COLUMNS = ['sWeight',\n",
    " 'particle_type',\n",
    " 'label',\n",
    " 'kinWeight',\n",
    " 'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.19 s, sys: 2.13 s, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.concat([train, closest_hits_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.9 s, sys: 7.62 s, total: 49.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.concat([train, closest_hits_features2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 2.88 s, total: 7.09 s\n",
      "Wall time: 7.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.concat([train, avg_dist_hits], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 1.49 s, total: 16.2 s\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.concat([test, closest_hits_features_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 1.52 s, total: 16.9 s\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test2 = pd.concat([test2, closest_hits_features_test2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 408 ms, total: 2.93 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_private = pd.concat([test_private, closest_hits_features_test_private], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.23 s, sys: 476 ms, total: 2.7 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_private2 = pd.concat([test_private2, closest_hits_features_test_private2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 540 ms, sys: 369 ms, total: 909 ms\n",
      "Wall time: 908 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.concat([test, avg_dist_hits_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 574 ms, sys: 293 ms, total: 867 ms\n",
      "Wall time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test2 = pd.concat([test2, avg_dist_hits_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 3.31 s, total: 25.2 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_part, validation = train_test_split(train, test_size=0.2, stratify=train.label, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавление информативных признаков, сохранение итогового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_hit_per_station(row):\n",
    "    result = [1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000]\n",
    "    mind = [0, 0, 0, 0]\n",
    "    hits = 0\n",
    "    for station in row[\"FOI_hits_S\"]:\n",
    "        x_distances_2 = (row[\"Lextra_X[\" + str(station) + \"]\"] - row[\"FOI_hits_X\"][hits])**2\n",
    "        y_distances_2 = (row[\"Lextra_Y[\" + str(station) + \"]\"] - row[\"FOI_hits_Y\"][hits])**2\n",
    "        distances_2 = x_distances_2 + y_distances_2\n",
    "        if mind[station] == 0:\n",
    "            mind[station] = distances_2\n",
    "            result[station*6 + 0] = x_distances_2\n",
    "            result[station*6 + 1] = y_distances_2\n",
    "            result[station*6 + 2] = row[\"FOI_hits_T\"][hits]\n",
    "            result[station*6 + 3] = row[\"FOI_hits_Z\"][hits]\n",
    "            result[station*6 + 4] = row[\"FOI_hits_DX\"][hits]\n",
    "            result[station*6 + 5] = row[\"FOI_hits_DY\"][hits]\n",
    "        else:\n",
    "            if mind[station] > distances_2:\n",
    "                mind[station] = distances_2\n",
    "                result[station*6 + 0] = x_distances_2\n",
    "                result[station*6 + 1] = y_distances_2\n",
    "                result[station*6 + 2] = row[\"FOI_hits_T\"][hits]\n",
    "                result[station*6 + 3] = row[\"FOI_hits_Z\"][hits]\n",
    "                result[station*6 + 4] = row[\"FOI_hits_DX\"][hits]\n",
    "                result[station*6 + 5] = row[\"FOI_hits_DY\"][hits]\n",
    "        hits = hits + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_hit_per_station_track2(row):\n",
    "    result = [1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000,1000]\n",
    "    mind = [0, 0, 0, 0]\n",
    "    hits = 0\n",
    "    for station in row[\"FOI_hits_S\"]:\n",
    "        x_distances_2 = (row[\"Lextra_X[\" + str(station) + \"]\"] - row[\"FOI_hits_X\"][hits])**2\n",
    "        y_distances_2 = (row[\"Lextra_Y[\" + str(station) + \"]\"] - row[\"FOI_hits_Y\"][hits])**2\n",
    "        distances_2 = x_distances_2 + y_distances_2\n",
    "        if mind[station] == 0:\n",
    "            mind[station] = distances_2\n",
    "            result[station] = x_distances_2\n",
    "            result[4 + station] = y_distances_2\n",
    "            result[8 + station] = row[\"FOI_hits_T\"][hits]\n",
    "            result[12 + station] = row[\"FOI_hits_Z\"][hits]\n",
    "            result[16 + station] = row[\"FOI_hits_DX\"][hits]\n",
    "            result[20 + station] = row[\"FOI_hits_DY\"][hits]\n",
    "        else:\n",
    "            if mind[station] > distances_2:\n",
    "                mind[station] = distances_2\n",
    "                result[station] = x_distances_2\n",
    "                result[4 + station] = y_distances_2\n",
    "                result[8 + station] = row[\"FOI_hits_T\"][hits]\n",
    "                result[12 + station] = row[\"FOI_hits_Z\"][hits]\n",
    "                result[16 + station] = row[\"FOI_hits_DX\"][hits]\n",
    "                result[20 + station] = row[\"FOI_hits_DY\"][hits]\n",
    "        hits = hits + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADsizeX = [31.6667, 63.0, 126.0, 252.0]\n",
    "PADsizeY = [38.8585, 77.9582, 156.158, 312.557]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_avg_dist(row):\n",
    "    result = [1000,1000]\n",
    "    hits = 0\n",
    "    distances_1 = 0\n",
    "    distances_2 = 0\n",
    "    for station in row[\"FOI_hits_S\"]:\n",
    "        x_distances_1 = (row[\"Lextra_X[\" + str(station) + \"]\"] - row[\"FOI_hits_X\"][hits])**2\n",
    "        y_distances_1 = (row[\"Lextra_Y[\" + str(station) + \"]\"] - row[\"FOI_hits_Y\"][hits])**2\n",
    "        \n",
    "        x_distances_2 = x_distances_1/(PADsizeX[station]**2)\n",
    "        y_distances_2 = y_distances_1/(PADsizeY[station]**2)\n",
    "        \n",
    "        distances_1 = distances_1 + x_distances_1 + y_distances_1\n",
    "        distances_2 = distances_2 + x_distances_2 + y_distances_2\n",
    "        hits = hits + 1\n",
    "     \n",
    "    result[0] = 1.0*distances_1/hits\n",
    "    result[1] = 1.0*distances_2/hits\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 47min 42s, sys: 15.2 s, total: 1h 47min 58s\n",
      "Wall time: 1h 47min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features2 = train.apply(find_closest_hit_per_station_track2, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features.to_hdf('data_itog.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features2.to_hdf('data_itog2.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closest_hits_features_test = test.apply(find_closest_hit_per_station, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "closest_hits_features_test2 = test.apply(find_closest_hit_per_station_track2, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 33s, sys: 10.6 s, total: 24min 44s\n",
      "Wall time: 24min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features_test_private = test_private.apply(find_closest_hit_per_station, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 5s, sys: 16.9 s, total: 26min 22s\n",
      "Wall time: 26min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest_hits_features_test_private2 = test_private2.apply(find_closest_hit_per_station_track2, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features_test.to_hdf('data_itog_test.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features_test2.to_hdf('data_itog_test2.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features_test_private.to_hdf('data_itog_test_private.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_hits_features_test_private2.to_hdf('data_itog_test_private2.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_hits = train.apply(find_avg_dist, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_hits.to_hdf('avg_dist_hits.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 58s, sys: 419 ms, total: 8min 58s\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "avg_dist_hits_test = test2.apply(find_avg_dist, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dist_hits_test.to_hdf('avg_dist_hits_test.hdf', mode='w', key='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base XGBoost-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgboost.XGBClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:31:07] Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "CPU times: user 2h 45min 38s, sys: 8.03 s, total: 2h 45min 46s\n",
      "Wall time: 11min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=train_part.weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.41 s, sys: 945 ms, total: 7.35 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7556692594512752"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)\n",
    "#0.7524629661308765 (80%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6991737755624489\n",
      "0.7192388677010243\n",
      "0.7222040875723421\n",
      "0.7275903681694574\n",
      "0.7338900780596765\n",
      "0.7319827913154457\n",
      "0.7377879676850043\n",
      "0.7454101485322719\n",
      "0.743777864020875\n",
      "CPU times: user 4h 10min 51s, sys: 4min 41s, total: 4h 15min 32s\n",
      "Wall time: 27min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_depth in range(3, 12, 1):\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=v_depth, l2_leaf_reg=5, learning_rate=0.1, \n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))\n",
    "\n",
    "#0.7210961960996494\n",
    "#0.7301291892159026\n",
    "#0.7422736150548254\n",
    "#0.7489491364059263\n",
    "#0.7513587393570458\n",
    "#0.7519879050217635\n",
    "#0.7513397901983102\n",
    "#0.760425103597202\n",
    "#0.7573003221726251\n",
    "#0.7500328908000631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433842562282784\n",
      "0.7435192247856279\n",
      "0.7454101485322719\n",
      "0.742733703813112\n",
      "0.740925366507245\n",
      "0.7393674632659628\n",
      "0.7392564553109914\n",
      "CPU times: user 6h 37min 13s, sys: 2min 59s, total: 6h 40min 13s\n",
      "Wall time: 35min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_l2_leaf_reg in range(3, 10, 1):\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=v_l2_leaf_reg, learning_rate=0.1, \n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7337988326126255\n",
      "0.7354050139745928\n",
      "0.745507760697995\n",
      "0.7412447904759015\n",
      "0.7458740305064446\n",
      "0.7443704048935286\n",
      "0.7424584967062693\n",
      "0.7417753832165102\n",
      "0.7399204737898198\n",
      "0.7454101485322719\n",
      "CPU times: user 5h 52min 11s, sys: 4min 9s, total: 5h 56min 21s\n",
      "Wall time: 37min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model2 = catboost.CatBoostClassifier(iterations=700, depth=10, l2_leaf_reg=6, learning_rate=0.06, rsm = 0.7,\n",
    "#                                      verbose=False, random_seed=27)\n",
    "for v_rsm in range(1, 11, 1):\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=5, learning_rate=0.1, rsm = v_rsm/10,\n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7152579608624362\n",
      "0.7275038516973219\n",
      "0.7454101485322719\n",
      "0.7411041030407106\n",
      "0.7377629156163057\n",
      "CPU times: user 4h 46min 27s, sys: 2min 5s, total: 4h 48min 33s\n",
      "Wall time: 25min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_learning_rate in [0.025, 0.05, 0.1, 0.2, 0.3]:\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=5, learning_rate=v_learning_rate, \n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7384598740396509\n",
      "0.7440981186384867\n",
      "CPU times: user 1h 53min 39s, sys: 51.1 s, total: 1h 54min 30s\n",
      "Wall time: 10min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_learning_rate in [0.075, 0.125]:\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=5, learning_rate=v_learning_rate, \n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7414363990428148\n",
      "0.7397084104669127\n",
      "CPU times: user 1h 53min 53s, sys: 50.7 s, total: 1h 54min 44s\n",
      "Wall time: 10min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_learning_rate in [0.09, 0.11]:\n",
    "    model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=5, learning_rate=v_learning_rate, \n",
    "                                      verbose=False, random_seed=27)\n",
    "    model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "    validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пробничек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7676367989852553\n"
     ]
    }
   ],
   "source": [
    "model2 = catboost.CatBoostClassifier(iterations=140, depth=10, l2_leaf_reg=6, learning_rate=0.1, rsm = 0.75,\n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=np.abs(train_part.weight.values), plot=False)\n",
    "validation_predictions2 = model2.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "print(scoring.rejection90(validation.label.values, validation_predictions2, sample_weight=validation.weight.values))\n",
    "#0.7449939644431877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### создаем модель Catboost и делаем прогноз для Track1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1d 8h 25min 54s, sys: 20min 42s, total: 1d 8h 46min 37s\n",
      "Wall time: 2h 24min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = catboost.CatBoostClassifier(iterations=5000, depth=10, l2_leaf_reg=6, learning_rate=0.05, rsm = 0.7,\n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=np.abs(train.weight.values), plot=False)\n",
    "\n",
    "model2.save_model('model_catboost_ver3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 s, sys: 893 ms, total: 39.4 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model2.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]        \n",
    "pd.DataFrame(data={\"prediction\": predictions}, index=test.index).to_csv(\"sample_submission_c1.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2d 2h 8min 11s, sys: 28min 6s, total: 2d 2h 36min 18s\n",
      "Wall time: 3h 39min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = catboost.CatBoostClassifier(iterations=8000, depth=10, l2_leaf_reg=6, learning_rate=0.04, rsm = 0.7,\n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=np.abs(train.weight.values), plot=False)\n",
    "\n",
    "model2.save_model('model_catboost_ver2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 920 ms, total: 1min 7s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model2.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]        \n",
    "pd.DataFrame(data={\"prediction\": predictions}, index=test.index).to_csv(\"sample_submission_c2.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### тестируем Catboost для Track2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 29min 27s, sys: 2min 46s, total: 6h 32min 14s\n",
      "Wall time: 28min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#7508.48\n",
    "model2 = catboost.CatBoostClassifier(iterations=772, depth=10, l2_leaf_reg=5, learning_rate=0.062, \n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=np.abs(train.weight.values), plot=False)\n",
    "\n",
    "model2.save_model('model_catboost_track2_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 31min, sys: 2min 44s, total: 6h 33min 45s\n",
      "Wall time: 28min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#7504.55\n",
    "model2 = catboost.CatBoostClassifier(iterations=775, depth=10, l2_leaf_reg=5, learning_rate=0.062, \n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=np.abs(train.weight.values), plot=False)\n",
    "\n",
    "model2.save_model('model_catboost_track2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 29min 10s, sys: 2min 43s, total: 6h 31min 54s\n",
      "Wall time: 28min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#7515.35\n",
    "model2 = catboost.CatBoostClassifier(iterations=771, depth=10, l2_leaf_reg=5, learning_rate=0.062, \n",
    "                                      verbose=False, random_seed=27)\n",
    "model2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=np.abs(train.weight.values), plot=False)\n",
    "\n",
    "model2.save_model('model_catboost_track2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05: 0.7438885700606036\n",
      "0.1: 0.7539971555720008\n",
      "0.15: 0.7599570552990959\n",
      "0.2: 0.7559458305416447\n",
      "0.3: 0.7498752615425813\n",
      "0.4: 0.7534909275289093\n",
      "CPU times: user 39min 8s, sys: 26.6 s, total: 39min 35s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_learning_rate in [0.05, 0.1, 0.15, 0.2, 0.3, 0.4]:\n",
    "    lg = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate=v_learning_rate, \n",
    "                n_estimators=100, \n",
    "                max_depth = 11,         \n",
    "                num_leaves=40, \n",
    "                random_state=27)\n",
    "\n",
    "    lg.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "               train_part.label.values, sample_weight=train_part.weight.values)\n",
    "\n",
    "    validation_predictions = lg.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "\n",
    "    print(str(v_learning_rate) + \": \" + str(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)))\n",
    "\n",
    "#0.05: 0.7380773999181911\n",
    "#0.1: 0.7452859696543559\n",
    "#0.15: 0.7438050448998444\n",
    "#0.2: 0.7418872001861442\n",
    "#0.3: 0.7496258688049903\n",
    "#0.4: 0.7417361506547251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3: 0.7518625423878622\n",
      "CPU times: user 5min 49s, sys: 4.29 s, total: 5min 53s\n",
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_learning_rate in [0.3]:\n",
    "    lg = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate=v_learning_rate, \n",
    "                n_estimators=100, \n",
    "                max_depth = 11,         \n",
    "                num_leaves=40, \n",
    "                random_state=27)\n",
    "\n",
    "    lg.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "               train_part.label.values, sample_weight=train_part.weight.values)\n",
    "\n",
    "    validation_predictions = lg.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "\n",
    "    print(str(v_learning_rate) + \": \" + str(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66: 0.7523140372164502\n",
      "0.67: 0.7523140372164502\n",
      "0.68: 0.749994779410802\n",
      "CPU times: user 13min 46s, sys: 13.3 s, total: 13min 59s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "            for v_colsample_bytree in [0.66,0.67,0.68]:\n",
    "                lg = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate = 0.3, \n",
    "                colsample_bytree = v_colsample_bytree, \n",
    "                subsample = 0.7,\n",
    "                reg_alpha = 1,\n",
    "                v_reg_lambda = 1,\n",
    "                n_estimators = 100, \n",
    "                max_depth = 11,         \n",
    "                num_leaves = 40, \n",
    "                random_state = 27)\n",
    "\n",
    "                lg.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "                           train_part.label.values, sample_weight=train_part.weight.values)\n",
    "\n",
    "                validation_predictions = lg.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "\n",
    "                print(str(v_colsample_bytree) + \": \" + str(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100: 0.7560070395023757\n",
      "200: 0.7546111963984424\n",
      "300: 0.7553296204679462\n",
      "400: 0.7515648987383036\n",
      "CPU times: user 20min 19s, sys: 17.8 s, total: 20min 37s\n",
      "Wall time: 20min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "            for v_n_estimators in [100,200,300,400]:\n",
    "                lg = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate = 0.2, \n",
    "                colsample_bytree = 0.66, \n",
    "                subsample = 0.7,\n",
    "                reg_alpha = 1,\n",
    "                v_reg_lambda = 1,\n",
    "                n_estimators = v_n_estimators, \n",
    "                max_depth = 11,         \n",
    "                num_leaves = 40, \n",
    "                random_state = 27)\n",
    "\n",
    "                lg.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "                           train_part.label.values, sample_weight=train_part.weight.values)\n",
    "\n",
    "                validation_predictions = lg.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "\n",
    "                print(str(v_n_estimators) + \": \" + str(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values)))\n",
    "#0.1: 0.7489462215351488\n",
    "#0.15: 0.7526157139780304\n",
    "#0.2: 0.7571553959266342\n",
    "#0.25: 0.7529741374159277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.66,\n",
       "        importance_type='split', learning_rate=0.3, max_depth=11,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=40, objective='binary',\n",
       "        random_state=27, reg_alpha=1, reg_lambda=0.0, silent=True,\n",
       "        subsample=0.7, subsample_for_bin=200000, subsample_freq=0,\n",
       "        v_reg_lambda=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate = 0.3, \n",
    "                colsample_bytree = 0.66, \n",
    "                subsample = 0.7,\n",
    "                reg_alpha = 1,\n",
    "                v_reg_lambda = 1,\n",
    "                n_estimators = 100, \n",
    "                max_depth = 11,         \n",
    "                num_leaves = 40, \n",
    "                random_state = 27)\n",
    "\n",
    "lg.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "                           train.label.values, sample_weight=train.weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.66,\n",
       "        importance_type='split', learning_rate=0.3, max_depth=11,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=40, objective='binary',\n",
       "        random_state=27, reg_alpha=1, reg_lambda=0.0, silent=True,\n",
       "        subsample=0.7, subsample_for_bin=200000, subsample_freq=0,\n",
       "        v_reg_lambda=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg2 = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                objective = 'binary',\n",
    "                learning_rate = 0.3, \n",
    "                colsample_bytree = 0.66, \n",
    "                subsample = 0.7,\n",
    "                reg_alpha = 1,\n",
    "                v_reg_lambda = 1,\n",
    "                n_estimators = 100, \n",
    "                max_depth = 11,         \n",
    "                num_leaves = 40, \n",
    "                random_state = 27)\n",
    "\n",
    "lg2.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values, \n",
    "                           train.label.values, sample_weight=train.weight.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 488 ms, total: 25 s\n",
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = lg.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]        \n",
    "pd.DataFrame(data={\"prediction\": predictions}, index=test.index).to_csv(\"sample_submission_lg.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f93c81f3438>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.booster_.save_model('lg_model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:20:26] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7592807395815973\n",
      "[06:26:05] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7592807395815973\n",
      "[06:31:45] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7592807395815973\n",
      "[06:37:25] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7792739743372552\n",
      "[06:46:37] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7826360544662789\n",
      "[06:55:49] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7793321774411841\n",
      "[07:05:02] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7899708482401512\n",
      "[07:18:11] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7919742459794071\n",
      "[07:31:17] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7929838709951461\n",
      "[07:44:23] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7934614938467769\n",
      "[08:01:42] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7940325610381087\n",
      "[08:19:14] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7902122356725646\n",
      "CPU times: user 1d 7h 1min 39s, sys: 1min 33s, total: 1d 7h 3min 13s\n",
      "Wall time: 2h 16min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_max_depth in range(3, 10, 2):\n",
    "    for v_min_child_weight in range(1, 6, 2):\n",
    "        model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=v_max_depth,\n",
    "         min_child_weight=v_min_child_weight, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "        model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train_part.label.values,\n",
    "          sample_weight=train_part.weight.values)\n",
    "        \n",
    "        validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "        print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:36:56] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7902122356725646\n",
      "[08:54:27] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7941769217644825\n",
      "[09:11:54] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7951455626935715\n",
      "[09:29:28] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7932563238216181\n",
      "[09:46:55] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7917126045790891\n",
      "CPU times: user 20h 14min 27s, sys: 40.1 s, total: 20h 15min 7s\n",
      "Wall time: 1h 27min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(0,5):\n",
    "    model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "             min_child_weight=5, gamma=i/10.0, subsample=0.8, colsample_bytree=0.8,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "    model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "                  train_part.label.values,\n",
    "                  sample_weight=train_part.weight.values)\n",
    "        \n",
    "    validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:04:49] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7938725119068626\n",
      "[10:20:20] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7926633311619761\n",
      "[10:37:46] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7964085040293832\n",
      "[10:56:58] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7942975234712555\n",
      "[11:12:50] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7951455626935715\n",
      "[11:30:20] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7887776781056736\n",
      "[11:49:52] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7934820503498864\n",
      "[12:05:39] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7952541224057071\n",
      "[12:23:14] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7932997257193426\n",
      "CPU times: user 1d 12h 23min 35s, sys: 1min 12s, total: 1d 12h 24min 47s\n",
      "Wall time: 2h 37min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_subsample in range(7,10):\n",
    "    for v_colsample_bytree in range(7,10):\n",
    "        model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "             min_child_weight=5, gamma=0.2, subsample=v_subsample/10.0, colsample_bytree=v_colsample_bytree/10.0,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "        model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "                  train_part.label.values,\n",
    "                  sample_weight=train_part.weight.values)\n",
    "        \n",
    "        validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "        print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:29:28] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7963100280108867\n",
      "[13:48:50] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7943658715598989\n",
      "[14:08:08] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7917684628076389\n",
      "[14:27:26] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7976379054256889\n",
      "[14:46:41] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.8044142882183166\n",
      "CPU times: user 22h 33min 42s, sys: 39.8 s, total: 22h 34min 22s\n",
      "Wall time: 1h 36min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_reg_alpha in [1e-5, 1e-2, 0.1, 1, 100]:\n",
    "    model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "             min_child_weight=5, gamma=0.2, subsample=0.7, colsample_bytree=0.9, reg_alpha=v_reg_alpha,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "    model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "                  train_part.label.values,\n",
    "                  sample_weight=train_part.weight.values)\n",
    "        \n",
    "    validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:45] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.8028579103869556\n",
      "CPU times: user 4h 29min 21s, sys: 7.75 s, total: 4h 29min 29s\n",
      "Wall time: 19min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_reg_alpha in [50]:\n",
    "    model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "             min_child_weight=5, gamma=0.2, subsample=0.7, colsample_bytree=0.9, reg_alpha=v_reg_alpha,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "    model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "                  train_part.label.values,\n",
    "                  sample_weight=train_part.weight.values)\n",
    "        \n",
    "    validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:27] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.7921211354696326\n",
      "[15:44:41] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "0.8030983338716395\n",
      "CPU times: user 8h 59min 36s, sys: 15.8 s, total: 8h 59min 52s\n",
      "Wall time: 38min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for v_reg_alpha in [25,75]:\n",
    "    model = xgboost.XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    "             min_child_weight=5, gamma=0.2, subsample=0.7, colsample_bytree=0.9, reg_alpha=v_reg_alpha,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "        \n",
    "    model.fit(train_part.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "                  train_part.label.values,\n",
    "                  sample_weight=train_part.weight.values)\n",
    "        \n",
    "    validation_predictions = model.predict_proba(validation.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values)[:, 1]\n",
    "        \n",
    "    print(scoring.rejection90(validation.label.values, validation_predictions, sample_weight=validation.weight.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final XGBoost-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:59:54] Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgboost.XGBClassifier(learning_rate=0.01, n_estimators=5000, max_depth=9,\n",
    "             min_child_weight=5, gamma=0.2, subsample=0.7, colsample_bytree=0.9, reg_alpha=100,\n",
    "             objective= 'binary:logistic', nthread=16, scale_pos_weight=1, seed=27)\n",
    "    \n",
    "model.fit(train.drop(utils.FOI_COLUMNS + utils.TRAIN_COLUMNS + KILL_COLUMNS, axis=1).values,\n",
    "          train.label.values,\n",
    "          sample_weight=train.weight.values)\n",
    "\n",
    "model.save_model('model_a2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.5 ms, sys: 70.4 ms, total: 102 ms\n",
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#model = xgboost.Booster({'nthread': 1})\n",
    "model = xgboost.XGBClassifier(n_jobs=-1)\n",
    "model.load_model('model_a1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 ms, sys: 149 ms, total: 172 ms\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model2 = catboost.CatBoostClassifier()\n",
    "model2.load_model('model_catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 221 ms, total: 335 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model3 = catboost.CatBoostClassifier()\n",
    "model3.load_model('model_catboost_ver2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lg = lgb.Booster(model_file='lg_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 12s, sys: 6.24 s, total: 11min 19s\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions1 = model.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22min 58s, sys: 11.7 s, total: 23min 10s\n",
      "Wall time: 23min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions1 = model.predict_proba(test_private.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.1 s, sys: 9.5 s, total: 58.6 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = model2.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 2.41 s, total: 1min 40s\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions2 = model2.predict_proba(test_private.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.05 s, sys: 493 ms, total: 5.55 s\n",
      "Wall time: 5.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions3 = lg.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.14 s, sys: 925 ms, total: 6.06 s\n",
      "Wall time: 6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions31 = lg2.predict_proba(test2.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.78 s, sys: 1.85 s, total: 11.6 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions31 = lg2.predict_proba(test_private2.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 219 ms, total: 1min 4s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions4 = model3.predict_proba(test.drop(utils.FOI_COLUMNS, axis=1).values)[:, 1]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (predictions1 + predictions2 + predictions31)/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 s, sys: 92 ms, total: 4.43 s\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pd.DataFrame(data={\"prediction\": predictions}, index=test_private.index).to_csv(\"sample_submission_s2.csv\", index_label=\"id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
